========================================= Part I ==============================================
Q1. 

(a) A, B, C, D, E
(b) A, C, E
(c) C, E
(d) B, D, E

Q2.

(a) True: As the OS is part of the same address space, it can invoke the user functions without any issues and the function will be executed with OS privilege. There will be issues while compiling the OS if function name identifiers are used instead of absolute addresses. Further, there can be security implications because the user code can corrupt the OS. (Arguing False with the last two phrases with specific security/compiler issue is fine too).

(b)  False: If the allocation of the kernel stack of the child process is delayed, the user space register state (saved in the parent kernel stack) can not be copied onto the child's kernel stack. Which means, when the child process is scheduled and returns back to the user mode, its user space state may not be the same as the parent process (violation of fork() semantic)

(c) False: It is not true in general and dependent on the time slice of the RR scheduling scheme. For example, with a large time slice, RR behaves like a  FIFO and results in lesser context switches compared to SCTF.

(d) True: Otherwise, the pages will be accessible from the user space even after being unmapped from the page table which may cause issues like correctness and security. Note that, if your answer considers (ptr + 8192) to be out of the range of allocated memory, the answer should mention why flushing the rest (ptr to ptr+8191) is required.

(e) False: Direct I/O write to a file require lookup of the write offset because the FS should invalidate/evict the blocks from the page cache before it performs direct write to the disk. Otherwise, the data in the page cache becomes stale. Another reason for lookup is to serve writes of size less than a block and the block is cached in the page cache

========================================= Part II ==============================================
Q1.
(a) Minimum: 1  (when main process pid is even, no children will be created)
    Maximum: 32 (when main process and all children pids are odd, it will be exponential)
    {Grading scheme: 1 + 1}

(b) Minimum: 6

when main process pid is even, mpid will remain unchanged i.e., 0 and dup() will be invoked 5 times

Maximum: 48  (Assuming fork does not increase R, only dup does)

    The following strategy leads to a solution with maximum value of R.

     "The main process PID is odd and at every iteration (except for the last), all children created will  have ODD pid values".

    ctr=0:  R value incremented by 1  (by the child (say C1) as mpid in C1 is 0)
    ctr=1:  R value incremented by 2  (by children C2 {parent P} and C3 {parent C1})
    ctr=2:  R value incremented by 4  (same as above)
    ctr=3:  R value incremented by 8

    If in the last iteration (ctr = 4) every child created have even PIDs, R will be incremented by 32.

    Total increment = 1 + 2 + 4 + 8 + 32 = 47
    Final value = 1 + 47 = 48

    Maximum: 128 (Assuming fork increases R by 1 for every fd pointing to R}

    The strategy remains the same.

   

    ctr=0:  value of R = 3 (one fork makes it 2 and one dup by C1)
    ctr=1:  value of R = 8 (two forks and two dups (note for C1 there are two FDs refering to STDOUT))    
    ctr=2:  value of R = 20 (Similar logic)                                                            
    ctr=3:  value of R = 48 (Similar logic)
    ctr=4:  value of R = 128 (Similar logic, but every process calls dup in this iterattion)

   

   

    {Grading scheme 1 + 3}

Q2. Open ended question. Will be evaluated in a subjective manner.

Q3. Open ended question. Will be evaluated in a subjective manner.

Q4.
(a) 2 ^ 53 bytes
(b) 2 ^ 33 bytes
(c) 64 - 37 - 5 - 10 = 12
(d)
    Minimum = 4GB + 510 * 8KB
    Explanation:
    #of entries freed in L4 = 2^19  ==> min #of L4 page table pages freed = 2^9 - 2 = 510
    #of entries freed in L3 = 510   ==> min #of L3 page table pages freed = 0
    #of entries freed in L2 = 0
    #of entries freed in L1 = 0

    Maximum = 4GB + 517 * 8KB
    #of entries freed in L4 = 2^19  ==> max #of L4 page table pages freed = 2^9 + 1 = 513
    #of entries freed in L3 = 513   ==> max #of L3 page table pages freed = 2
    #of entries freed in L2 = 2     ==> max #of L2 page table pages freed = 2
    #of entries freed in L1 = 2     ==> max #of page table pages freed = 0   (can not be freed, process is alive)

Q5. The syncronization scheme will not meet mutual exclusion requirements as shown in the following execution order.

     - T0 invokes unlock while T1 is waiting at the while loop.
     - T0 sets turn = 1 and gets descheduled
     - T1 gets the lock, enters the CS and calls unlock
     - T1 sets the turn = 0 and invokes lock, stuck in the while condition
     - T0 sets flag[0] = 0 and gets descheduled
     - At this point T1 can enter the CS (as flags[0] = 0)
     - While T1 is in CS, T0 calls lock again and enters the CS (as turn = 0)

    (Any other order showing the violation is also fine)

Q6. There are two problems in the code.

Major problem: if AtomicMove(Queue *Q1, Queue *Q2) and AtomicMove(Queue *Q2, Queue *Q1) are called concurrently, there can be a deadlock. This can be solved by proper ordering of the locks (using the lock order based on some key like the value of Queue object pointer)

Minor problem: If AtomicMove(Queue *Q1, Queue *Q1) is called, there will be a deadlock. This can be solved by checking the pointers before acquiring any locks.
{Grading scheme: 4 + 1}

Q7.
(a) (8 + 4*1024 + 4 * 1024 * 1024) * (4096/256)    // 256 byte per entry
    (Above answer - 2 will be accepted as special entries like "." and ".." are created by most file systems by default)

(b) Min: 5 + 1 = 6 blocks (At every level of directory the next level is found in the first block. One for reading the file)
    Max: 5 * (8 + 4 + 4*1024 + 4 + 4*1024 + 4*1024*1024) + 1 (At every level, the entry is found in the last block of the directory)

    {Grading scheme: 1 + 2}

(c) Min: 1  (Everything is a cache hit except for the file block)
    Max: 5 * (8 + 4 + 4*1024 + 4 + 4*1024 + 4*1024*1024) + 3

    Explanation: At every level, the entry is found in the last block of the directory and the file block is the last block of the file. No cache hit for indexes and directory content at any level.  The calculation is same as the previous question for the lookup. For the file data, we need to read two indirect index blocks and one data block.
